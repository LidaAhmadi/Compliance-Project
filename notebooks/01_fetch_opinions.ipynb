{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec328fe-8112-4757-b30d-7199a14502ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "In this initial step, I'll set up the notebook's environment. This involves three key actions:\n",
    "1.  Importing all necessary standard and third-party Python libraries.\n",
    "2.  Programmatically setting the project's root directory to ensure all relative paths for data and source code work correctly.\n",
    "3.  Importing my custom configuration variables and functions from the `config.py` and `src/` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093841f7-1840-4789-8e41-d85b27a6e52a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already at project root: /Users/lidasmac/compliance-nlp\n"
     ]
    }
   ],
   "source": [
    "# --- Foundational Library Imports ---\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# --- Project Root Setup ---\n",
    "# This block ensures the notebook's working directory is always the project root (compliance-nlp/).\n",
    "# This makes all file paths for data and source code consistent and reproducible.\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    os.chdir(current_dir.parent)\n",
    "    print(f\"Changed working directory to project root: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Already at project root: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d550b0-ad18-4641-9284-7a165d6ea93c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Custom & Configuration Imports ---\n",
    "# This cell can only run correctly after the working directory has been set above.\n",
    "from config import (\n",
    "    API_TOKEN, QUERY, PAGE_SIZE, DATA_DIR, MIN_TEXT_LENGTH,\n",
    "    TARGET_RULING_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b7546-a4df-4b72-89ec-35dada42e521",
   "metadata": {},
   "source": [
    "## Step 2. Prepare API Request & Directories\n",
    "\n",
    "Next, I will prepare the components needed to make a request to the CourtListener API and ensure the output directory for the data is ready.\n",
    "\n",
    "-   **`headers`**: This dictionary contains my API token for authentication. The `\"Authorization\"` key must follow the format `\"Token <my_token>\"`.\n",
    "-   **`params`**: This dictionary specifies the query parameters for the API call, such as my search term, the sort order, and the number of results to return per page.\n",
    "-   **`os.makedirs`**: I use this function to ensure that the folder where I'll save the ruling files exists. If it doesn't, this command creates it automatically.\n",
    "\n",
    "This block prepares everything needed to begin retrieving data securely and saving it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079cc99d-8dec-4c2e-a011-c48514585d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Prepare API Request & Directories ---\n",
    "\n",
    "# Set up the authentication headers with the required space\n",
    "headers = {\n",
    "    \"Authorization\": f\"Token {API_TOKEN}\"\n",
    "}\n",
    "\n",
    "# Set up the parameters for a reproducible query\n",
    "params = {\n",
    "    \"search\": QUERY,\n",
    "    \"order_by\": \"-id\",  # Sort by unique ID descending for deterministic results\n",
    "    \"page_size\": PAGE_SIZE\n",
    "}\n",
    "\n",
    "# Ensure the output directory for raw data exists\n",
    "# This should target the 'raw' sub-directory.\n",
    "raw_data_dir = Path(DATA_DIR)/ \"raw\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ca298-9ce0-4db6-b697-e0b195cfa3cc",
   "metadata": {},
   "source": [
    "## 3. Execute Data Fetching Pipeline\n",
    "\n",
    "With the setup complete, I will now execute the main data collection script. The goal is to ensure my local `data/raw/` directory contains a specific number of rulings, with the target amount controlled by a variable in my central `config.py` file.\n",
    "\n",
    "-   **Configuration-Driven:** The script only runs if the number of local files is less than the `TARGET_RULING_COUNT` defined in `config.py`. For this phase, I have set this value to 74.\n",
    "-   **Idempotent Logic:** Before downloading, the script checks if a file with a specific `opinion_id` already exists. If it does, the download is skipped. This allows the script to be run multiple times to safely \"top up\" the dataset without creating duplicates.\n",
    "-   **Reproducible Results:** It uses stable sorting (`order_by: \"-id\"`) to ensure the set of downloaded documents is always the same.\n",
    "\n",
    "This robust process gives me full control over my dataset size while making the collection process reproducible and easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43303ba3-f46a-4cbe-bc23-4a3c49f20754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Target of 74 files met or exceeded.\n",
      "   Directory 'data/raw' already contains 74 files.\n",
      "   Halting script. No new files will be downloaded.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the final output directory ---\n",
    "raw_data_dir = Path(DATA_DIR) / \"raw\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 2. SAFETY CHECK & MAIN LOGIC ---\n",
    "try:\n",
    "    current_file_count = len(list(raw_data_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    if current_file_count >= TARGET_RULING_COUNT:\n",
    "        print(f\"   Target of {TARGET_RULING_COUNT} files met or exceeded.\")\n",
    "        print(f\"   Directory '{raw_data_dir}' already contains {current_file_count} files.\")\n",
    "        print(\"   Halting script. No new files will be downloaded.\")\n",
    "    else:\n",
    "        print(f\"Current file count is {current_file_count}. Target is {TARGET_RULING_COUNT}.\")\n",
    "        print(\"Proceeding to download missing files...\")\n",
    "        \n",
    "        # --- 3. Main Fetching Loop ---\n",
    "        saved_count = 0\n",
    "        skipped_count = 0\n",
    "        page = 1\n",
    "\n",
    "        while (saved_count + current_file_count) < TARGET_RULING_COUNT:\n",
    "            print(f\"🔍 Fetching page {page}...\")\n",
    "            params[\"page\"] = page\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(\"https://www.courtlistener.com/api/rest/v4/opinions/\", headers=headers, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json() \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"API Request failed: {e}\")\n",
    "                break\n",
    "\n",
    "            results = data.get(\"results\", [])\n",
    "            if not results:\n",
    "                print(\"No results on this page. Halting.\")\n",
    "                break\n",
    "\n",
    "            for item in results:\n",
    "                if (saved_count + current_file_count) >= TARGET_RULING_COUNT:\n",
    "                    break\n",
    "\n",
    "                opinion_id = item.get(\"id\")\n",
    "                if not opinion_id: continue\n",
    "\n",
    "                filepath = raw_data_dir / f\"opinion_{opinion_id}.txt\"\n",
    "\n",
    "                if filepath.exists():\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                text = item.get(\"plain_text\") or item.get(\"html_with_citations\") or \"\"\n",
    "                if len(text.strip()) < MIN_TEXT_LENGTH: continue\n",
    "\n",
    "                with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "\n",
    "                saved_count += 1\n",
    "                print(f\"  Saved ({saved_count}): {filepath.name}\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            if not data.get(\"next\"):\n",
    "                print(\"\\nNo more pages available from API. Halting.\")\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "\n",
    "        print(f\"\\n Fetching complete! Newly saved: {saved_count} rulings. Skipped: {skipped_count} existing files.\")\n",
    "        print(f\"Total files in directory: {len(list(raw_data_dir.glob('*.txt')))}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa750d5-a443-4a1d-a2fa-d08d06fe8e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
